{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Introducción al Procesamiento del Lenguaje Natural 2018 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *notebook* de Python contiene las instrucciones para la segunda entrega del curso Introducción al Procesamiento de Lenguaje Natural. En el mismo se encontrará con instrucciones en bloques de texto y bloques de código para completar. Si bien no debe modificar la estructura base del notebook, puede agregar los bloques de texto o código que considere pertinentes para aportar claridad a la entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que su entorno de Python 3 contiene todas las bibliotecas necesarias. Ejecute el bloque código a continuación para importar las bibliotecas nltk, sklearn y otras que le serán de utilidad. Verifique que se importan sin errores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import os \n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe el corpus contenido en el directorio *restaurante-review-dataset* extraído de [1]. Note la partición en entrenamiento (train), validación (val) y evaluación (test). Ejecute el bloque a continuación para cargar el contenido del corpus en tres variable: *train*, *validation* y *test*. Se utiliza como estructura de datos una lista de pares (comentario, valor), donde comentario es una string con el comentario y valor corresponde a la string \"POS\" o \"NEG\" si el comentario es positivo o negativo, respectivamente.\n",
    " \n",
    "[1] Dubiau, L., & Ale, J. M. (2013). Análisis de Sentimientos sobre un Corpus en Español: Experimentación con un Caso de Estudio. In Proceedings of the 14th Argentine Symposium on Artificial Intelligence, ASAI (pp. 36-47).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, val):\n",
    "    data = []\n",
    "    for file in os.listdir(directory):\n",
    "        with open(os.path.join(directory, file)) as f:\n",
    "            file_data = json.load(f)\n",
    "            data += [(l,val) for l in file_data]\n",
    "    return data\n",
    "\n",
    "corpus_train_dirs = [\n",
    "    (\"./restaurante-review-dataset/train-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/train-pos/\", \"POS\"),\n",
    "]\n",
    "corpus_val_dirs = [\n",
    "    (\"./restaurante-review-dataset/val-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/val-pos/\", \"POS\"),\n",
    "]\n",
    "corpus_test_dirs = [\n",
    "    (\"./restaurante-review-dataset/test-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/test-pos/\", \"POS\"),\n",
    "]\n",
    "\n",
    "train, validation, test = [],[],[]\n",
    "for d,v in corpus_train_dirs:\n",
    "    train += load_data(d, v)\n",
    "for d,v in corpus_val_dirs:\n",
    "    validation += load_data(d, v)\n",
    "for d,v in corpus_test_dirs:\n",
    "    test += load_data(d, v)\n",
    "\n",
    "random.Random(1234).shuffle(train)\n",
    "random.Random(2345).shuffle(validation)\n",
    "random.Random(3456).shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue en pantalla la cantidad de elementos positivos, negativos y totales de cada partición del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la partición 'train' hay un total de 34506 comentarios de los cuales 23114 son positivos y 11392 son negativos.\n",
      "\n",
      "En la partición 'validation' hay un total de 8587 comentarios de los cuales 5582 son positivos y 3005 son negativos.\n",
      "\n",
      "En la partición 'test' hay un total de 9348 comentarios de los cuales 6112 son positivos y 3236 son negativos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainPOS = sum(1 for comentario in train if comentario[1] == 'POS')\n",
    "trainTOT = len(train)\n",
    "trainNEG = trainTOT - trainPOS\n",
    "\n",
    "validationPOS = sum(1 for comentario in validation if comentario[1] == 'POS')\n",
    "validationTOT = len(validation)\n",
    "validationNEG = validationTOT - validationPOS\n",
    "\n",
    "testPOS = sum(1 for comentario in test if comentario[1] == 'POS')\n",
    "testTOT = len(test)\n",
    "testNEG = testTOT - testPOS\n",
    "\n",
    "print(\"En la partición 'train' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(trainTOT, trainPOS, trainNEG))\n",
    "print(\"En la partición 'validation' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(validationTOT, validationPOS, validationNEG))\n",
    "print(\"En la partición 'test' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(testTOT, testPOS, testNEG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los *word vectors* son representaciones vectoriales de las palabras construidas a partir de grandes colecciones de texto. Junto a este *notebook* se imparte un reportorio de vectores construido a partir de un corpus en español usando *skip-gram* con *negative sampling* (SGNS)[1]\n",
    "\n",
    "En esta sección cargará en memoria y utilizará el repertorio de vectores impartido. Además, se evaluará la cobertura del repertorio en el corpus y se estudiará las palabras del corpus no contempladas en el repertorio de vectores (*out-of-vocabulary terms*).\n",
    "\n",
    "En el directorio *vectores* se encuentran dos archivos:\n",
    "\n",
    "- sgns_spvectors_300.txt con la lista de palabras del repertorio\n",
    "- sgns_spvectors_300.npy con la matriz que contiene cada vector\n",
    "\n",
    "Defina un mecanismo para cargar en memoria los vectores y para obtener en tiempo eficiente el vector correspondiente a una palabra. Tenga en cuenta lo siguiente:\n",
    "\n",
    "- puede serle útil un diccionario que a cada palabra le corresponda su índice en la matriz\n",
    "- resuelva que hacer con las palabras que no están en el repertorio de vectores\n",
    "\n",
    "\n",
    "[1] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vectors = np.load('./vectores/sgns_spvectors_300.npy')\n",
    "\n",
    "with open('./vectores/sgns_spvectors_300.txt', 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "_, totalColumnsVectors = vectors.shape\n",
    "\n",
    "numToWord = dict(list(enumerate(words)))\n",
    "wordToNum = {v: k for k, v in numToWord.items()}\n",
    "\n",
    "def getVector(vectors, word):\n",
    "    try:\n",
    "        vec = vectors[wordToNum[word]]\n",
    "    except KeyError:\n",
    "        return [0 for _ in range(totalColumnsVectors)]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realice pruebas con los vectores almacenados. En el siguiente bloque de código realice lo siguiente:\n",
    "\n",
    "1. Defina una función de similitud entre vectores\n",
    "2. Imprima la similitud entre los vectores de las palabras de ejemplo\n",
    "3. Defina un conjunto de pares de palabras del repertorio de vectores (*pares_estudiante*)\n",
    "4. Imprima la similitud de los vectores de las palabras definidas en el paso anterior\n",
    "5. Imprima el vector correspondiente a una palabra que no se encuentre en el repertorio de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto 'pares':\n",
      "\n",
      "La similitud entre 'bueno' y 'excelente' es 0.44070714712142944.\n",
      "La similitud entre 'bueno' y 'buena' es 0.5369178056716919.\n",
      "La similitud entre 'bueno' y 'malo' es 0.7269262075424194.\n",
      "La similitud entre 'malo' y 'espantoso' es 0.5346347093582153.\n",
      "La similitud entre 'comida' y 'ambiente' es 0.23836146295070648.\n",
      "La similitud entre 'comida' y 'bebida' es 0.6403059959411621.\n",
      "La similitud entre 'comida' y 'postre' es 0.46853193640708923.\n",
      "La similitud entre 'comida' y 'sabor' es 0.44875413179397583.\n",
      "La similitud entre 'servicio' y 'comida' es 0.2339814007282257.\n",
      "La similitud entre 'servicio' y 'ambiente' es 0.22486859560012817.\n",
      "La similitud entre 'ambiente' y 'calor' es 0.3984523117542267.\n",
      "La similitud entre 'frío' y 'calor' es 0.7722591757774353.\n",
      "\n",
      "Conjunto 'pares_estudiante':\n",
      "\n",
      "La similitud entre 'bodka' y 'vodka' es 0.5515549182891846.\n",
      "La similitud entre 'manuela' y 'marea' es 0.034327760338783264.\n",
      "La similitud entre 'salado' y 'dulce' es 0.5086449384689331.\n",
      "La similitud entre 'rico' y 'sabroso' es 0.38383251428604126.\n",
      "La similitud entre 'agua' y 'salada' es 0.6080362796783447.\n",
      "La similitud entre 'postre' y 'dulce' es 0.4334905445575714.\n",
      "La similitud entre 'ambiente' y 'agradable' es 0.4512560963630676.\n",
      "La similitud entre 'tecnologia' y 'idem' es 0.14142969250679016.\n",
      "La similitud entre 'pista' y 'carreras' es 0.3466614782810211.\n",
      "La similitud entre 'administración' y 'empresas' es 0.47153720259666443.\n",
      "La similitud entre 'anterior' y 'posterior' es 0.5473390817642212.\n",
      "La similitud entre 'buenos' y 'aires' es 0.8710863590240479.\n",
      "La similitud entre 'francia' y 'españa' es 0.6555995941162109.\n",
      "La similitud entre 'francia' y 'espana' es 0.29281607270240784.\n",
      "La similitud entre 'france' y 'spain' es 0.45504653453826904.\n",
      "La similitud entre 'alejandro' y 'magno' es 0.5100721120834351.\n",
      "La similitud entre 'año' y 'nuevo' es 0.4988631308078766.\n",
      "La similitud entre 'caño' y 'caños' es 0.692112147808075.\n",
      "La similitud entre 'el' y 'la' es 0.6048038601875305.\n",
      "La similitud entre 'eso' y 'esa' es 0.6348000764846802.\n",
      "\n",
      "El vector correspondiente a una palabra que no se encuentre en el repertorio de vectores es: \n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def similarity(vector1, vector2):\n",
    "    if ((norm(vector1) == 0) or (norm(vector2) == 0)):\n",
    "        return 0\n",
    "    return 1 - cosine(vector1, vector2)\n",
    "\n",
    "pares = [\n",
    "    ('bueno','excelente'),\n",
    "    ('bueno','buena'),\n",
    "    ('bueno','malo'),\n",
    "    ('malo','espantoso'),\n",
    "    ('comida', 'ambiente'),\n",
    "    ('comida', 'bebida'),\n",
    "    ('comida', 'postre'),\n",
    "    ('comida', 'sabor'),\n",
    "    ('servicio', 'comida'),\n",
    "    ('servicio', 'ambiente'),\n",
    "    ('ambiente', 'calor'),\n",
    "    ('frío', 'calor'),\n",
    "]\n",
    "\n",
    "print(\"Conjunto 'pares':\\n\")\n",
    "\n",
    "for pair in pares:\n",
    "    vector0 = getVector(vectors, pair[0])\n",
    "    vector1 = getVector(vectors, pair[1])\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(pair[0], pair[1], similarity(vector0, vector1)))\n",
    "\n",
    "print(\"\\nConjunto 'pares_estudiante':\\n\")\n",
    "\n",
    "pares_estudiante = [\n",
    "    ('bodka', 'vodka'),\n",
    "    ('manuela', 'marea'),\n",
    "    ('salado', 'dulce'),\n",
    "    ('rico', 'sabroso'),\n",
    "    ('agua', 'salada'),\n",
    "    ('postre', 'dulce'),\n",
    "    ('ambiente', 'agradable'),\n",
    "    ('tecnologia', 'idem'),\n",
    "    ('pista', 'carreras'),\n",
    "    ('administración', 'empresas'),\n",
    "    ('anterior', 'posterior'),\n",
    "    ('buenos', 'aires'),\n",
    "    ('francia', 'españa'),\n",
    "    ('francia', 'espana'),\n",
    "    ('france', 'spain'),\n",
    "    ('alejandro', 'magno'),\n",
    "    ('año', 'nuevo'),\n",
    "    ('caño', 'caños'),\n",
    "    ('el', 'la'),\n",
    "    ('eso', 'esa'),\n",
    "] \n",
    "\n",
    "for pair in pares_estudiante:\n",
    "    vector0 = getVector(vectors, pair[0])\n",
    "    vector1 = getVector(vectors, pair[1])\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(pair[0], pair[1], similarity(vector0, vector1)))\n",
    "    \n",
    "print(\"\\nEl vector correspondiente a una palabra que no se encuentre en el repertorio de vectores es: \\n\", getVector(vectors, 'palabrafueradelrepertorio'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué observa en los resultados obtenidos?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Para analizar los resultados obtenidos debemos tener en cuenta el funcionamiento del modelo skip-gram. Dicho modelo es implementado como una red neuronal de una única capa oculta que tiene como entrada un vector 'one-hot' (esto es, un vector de largo _n = cantidad de tokens en el corpus_ y con valor 1 en la posición que corresponde a la palabra ingresada y 0 en los demás valores) que representa una palabra, devolviendo como salida un vector de probabilidades de que cada palabra del corpus de entrenamiento se encuentre en el contexto de la palabra ingresada (o sea, en su proximidad). Luego, los vectores se obtienen de la matriz resultante en la capa oculta de la red. Este modelo forma parte del conjunto de modelos utilizados en _word2vec_.\n",
    "De este modelo se deriva que la distancia entre dos palabras en su representación vectorial nos permite obtener una medida de si una de ellas aparece en contextos iguales a la otra en nuestro corpus de entrenamiento.\n",
    "\n",
    "Es así que podemos observar, por ejemplo, que las palabras 'bueno' y 'malo' aparecen en el mismo contexto varias veces ya que tienen un valor de similitud alto. Lo mismo ocurre con palabras como 'frío' y 'calor', 'francia' y 'españa' mientras que palabras como 'manuela' y 'marea' no aparecen prácticamente nunca en el mismo contexto. Las palabras 'buenos' y 'aires' son de las que mayor valor de similitud tienen, ya que suelen aparecer juntas conformando un nombre propio. Parece ser que no se hizo en este caso, pero en [1] recomiendan tratar este tipo de \"frases\" como una palabra en sí, manteniendo separado el significado de las palabras cuando se encuentran aparte de cuando se encuentran juntas.\n",
    "También podemos ver que pronombres con el mismo significado pero que varían en género tienen una similitud muy alta, lo cual es previsible.\n",
    "\n",
    "Cabe destacar ciertos casos en los que podría suceder que intuitivamente se piense que la similitud debería rondar cierto valor (a nuestro juicio), pero que no resulta así. Tales son los casos como 'francia' y 'espana' (esta última es escrita así cuando el escritor tiene un teclado en inglés), 'pista' y 'carreras' o 'rico' y 'sabroso'. Esto puede suceder porque las palabras no ocurrían en el mismo contexto lo suficiente como para impactar en el valor de similitud. Otro causante de esto es que la ventana de contexto utilizada (esto es, cuantas palabras se consideran hacia la derecha y hacia la izquierda de la palabra objetivo) no tenga un tamaño suficiente para recoger ciertas palabras en el contexto de la palabra objetivo, o también que la ventana no sea simétrica (por ejemplo, considera 8 palabras antes de la objetivo y 1 palabra luego de la misma). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el bloque de código a continuación realice lo siguiente:\n",
    "- Separe el corpus en palabras con nltk.wordpunct_tokenize (todas la partes: train, validacion y test)\n",
    "- Convierta las palabras a minúsculas dado que el repertorio de vectores está en minúsculas\n",
    "- Almacene las palabras resultantes en una variable llamada *vocabulario*. Considere una estructura adecuada para no tener palabras repetidas.\n",
    "- Despliegue en pantalla la cantidad de palabras de *vocabulario*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario tiene 53489 palabras.\n"
     ]
    }
   ],
   "source": [
    "vocabulario = set()\n",
    "\n",
    "for comment in train + validation + test:\n",
    "    tokenizedComment = nltk.wordpunct_tokenize(comment[0].lower())\n",
    "    for word in tokenizedComment:\n",
    "        vocabulario.add(word)\n",
    "\n",
    "print(\"El vocabulario tiene \" + str(len(vocabulario)) + \" palabras.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construya los siguientes dos conjuntos:\n",
    "\n",
    "1. Palabras de *vocabulario* que tienen un vector asociado en el repertorio de vectores.\n",
    "2. Palabras de *vocabulario* que **no** tienen un vector en el repertorio de vectores.\n",
    "\n",
    "Imprima la cantidad de palabras de cada conjunto. Imprima además un muestreo de las palabras del conjunto 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras que tienen un vector asociado: 53489\n",
      "Cantidad de palabras que NO tienen un vector asociado: 9278\n",
      "\n",
      "dorsia\n",
      "resturant\n",
      "malisimos\n",
      "infaltablr\n",
      "agregarona\n",
      "browny\n",
      "favorrrrrrr\n",
      "tobanyaki\n",
      "atendiö\n",
      "rneado\n",
      "desgustacion\n",
      "bocconotto\n",
      "agrergaron\n",
      "morsilla\n",
      "torillas\n",
      "recomendóel\n",
      "!!!!..\n",
      "rools\n",
      "diasculpas\n",
      "pmadero\n",
      "cumpliamos\n",
      "ambientaón\n",
      "pavè\n",
      "recocinados\n",
      "marucuyá\n",
      "histéricamante\n",
      "caipirvoska\n",
      ":),\n",
      "sweetbreads\n",
      "sacarn\n",
      "ccaro\n",
      "hugoheadrecomiendo\n",
      "postrecon\n",
      "negativisima\n",
      "excursao\n",
      "nautural\n",
      "tandoris\n",
      "gamberetti\n",
      "chopeada\n",
      "deshabridos\n",
      "bueniiiiisimos\n"
     ]
    }
   ],
   "source": [
    "hasVector = set()\n",
    "hasVectorNot = set()\n",
    "\n",
    "for word in vocabulario:\n",
    "    try:\n",
    "        vec = vectors[wordToNum[word]]\n",
    "    except KeyError:\n",
    "        hasVectorNot.add(word)\n",
    "    hasVector.add(word)\n",
    "    \n",
    "print(\"Cantidad de palabras que tienen un vector asociado: {}\".format(len(hasVector)))\n",
    "print(\"Cantidad de palabras que NO tienen un vector asociado: {}\\n\".format(len(hasVectorNot)))\n",
    "\n",
    "for word in enumerate(list(hasVectorNot)):\n",
    "    print(word[1])\n",
    "    if (word[0] == 40): break;\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué observa en el muestreo de palabras que no tienen un vector asociado (conjunto 2)?\n",
    "\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Las 20 palabras impresas son en su mayoría palabras que tienen errores ortográficos o \"typos\" (abreviatura de _typographical error_ en español \"error tipográfico\"). Otras palabras que también aparecen en el muestreo son emoticones (':)'), algunas puntuaciones \"extrañas\" ('!!!!..') y palabras que son escritas haciendo énfasis en algun aspecto (como 'bueniiiiisimos' o 'favorrrrrrr') , como también algunas que, aunque no son tan raras, simplemente pueden no aparecen en el corpus de entrenamiento (como 'resturant' o 'histéricamante'). También aparecen palabras que son heredadas de otros idiomas (como 'chopeada', 'browny' o 'sweetbreads').\n",
    "\n",
    "Esto es un suceso común, ya que los comentarios son escritos por personas de todo estrato social y edad, lo que lleva a que se encuentren palabras con faltas ortográficas o \"raras\". Además, es común que varias letras se intercambien por otras cuando se escribe en el teclado (\"typo\").\n",
    "También se debe considerar que los lenguajes se encuentran en constante evolución, y que dependiendo de los diferentes tiempos de donde se comparen texto, se pueden encontrar palabras que no existían en el espacio temporal de uno pero si en otro.\n",
    "Otro factor a tener en cuenta es que los corpus no traten sobre el mismo tema, provocando que palabras del lenguaje específico de los comentarios de restaurantes no se encuentren en el corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación vectorial de la oración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de Palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice una representación de bolsa de palabras con *stemming* para los comentarios del corpus considerando únicamente los conjuntos de entrenamiento y validación. Utilice la clase *sklearn.CountVectorizer* con una configuración de parámetros con considere adecuada. Esta representación será utilizada posteriormente para realizar clasificiación supervisada.\n",
    "\n",
    "**Sugerencia:** Utilice el parámetro *min_df* y *max_df* para reducir la dimensión del vector de la bolsa de palabras. Se sugiere que la dimensión de la representación sea menor a 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from copy import copy\n",
    "\n",
    "spanish_stemmer = SpanishStemmer()\n",
    "\n",
    "tokenRegex = '[a-záéíóúñ]{3,}'\n",
    "transf = sklearn.feature_extraction.text.CountVectorizer(max_df=0.2, min_df=400, ngram_range=(1,1), analyzer='word', \n",
    "                                                         lowercase=True, token_pattern=tokenRegex, stop_words=None)\n",
    "\n",
    "# Se define una nueva función que servira como nuevo parametro tokenizer del constructor CountVectorizer\n",
    "def stem_tokenizer(text):\n",
    "    tokenizer = transf.build_tokenizer()\n",
    "    return [spanish_stemmer.stem(word) for word in tokenizer(text)]\n",
    "\n",
    "trainCom = [comentario for (comentario, valor) in train]\n",
    "validationCom = [comentario for (comentario, valor) in validation]\n",
    "comments = trainCom + validationCom\n",
    "\n",
    "transf_with_stem = copy(transf).set_params(tokenizer=stem_tokenizer)\n",
    "transf_with_stem.fit(comments)\n",
    "\n",
    "vectores_with_stem = transf_with_stem.transform(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente bloque de código realice lo siguiente:\n",
    "\n",
    "- Despliegue la representacion (bow) de la oración presentada como ejemplo\n",
    "- Despliegue además la cantidad de palabras de la bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La representación de la oración es:   (0, 386)\t2\n",
      "La bolsa de palabras tiene 486 palabras.\n"
     ]
    }
   ],
   "source": [
    "oracion_ej = 'Muy pero muy buena rica la comida y muy ricas tartas'\n",
    "\n",
    "# COMPLETE A PARTIR DE AQUI\n",
    "bow = transf_with_stem.transform([oracion_ej])\n",
    "print(\"La representación de la oración es: \" + str(bow))\n",
    "diccionario_with_stem = transf_with_stem.get_feature_names()\n",
    "print(\"La bolsa de palabras tiene \" + str(len(diccionario_with_stem)) + \" palabras.\")\n",
    "#print(vectores_with_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el bloque de código a continuación para definir la funcion *imprimir_tiempo*. Esta función despliega en pantalla el tiempo transcurrido a partir del timestamp pasado como parámetro. Si desea puede utilizarla para medir el tiempo de sus ejecuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def imprimir_tiempo(ts):\n",
    "    print(\"--- %s mins ---\" % (float(time.time() - ts)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente la función *data2Xy_bow* cuyo encabezado se presenta en el bloque de código a continuación. La función transforma en vectores a los comentarios con la bolsa de palabras almacenándolos en X y sus etiquetas en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2Xy_bow(bow, data):\n",
    "    X = bow.transform([comentario for (comentario, etiqueta) in data])\n",
    "    y = [etiqueta for (comentario,etiqueta) in data]\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere la lista de pares de comentarios *lista_comentarios*. En la lista *lista_comentarios_estudiante* escriba pares de comentarios que considere pertinentes para ver su similitud según el *bow* definido. Imprima en pantalla los comentarios de ambas listas junto a la similaridad obtenida según la representación de *bow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre 'muy rica la comida, buenas pizzas' y 'excelente pizza la salsa estaba muy rica' es 0.7071067811865476.\n",
      "La similitud entre 'no me gustó para nada. mala atención' y 'me pareció todo bastante malo' es 0.33333333333333337.\n",
      "La similitud entre 'que buen servicio, hay que volver' y 'excelente todo, me verán seguido por ahí' es 0.0.\n",
      "La similitud entre 'las tartas no me gustaron' y 'muy bueno servicio' es 0.0.\n",
      "La similitud entre 'Es todo muy muy rico y de alta calidad!' y 'muy muy rico todo. servicios excellente. buen curry.' es 0.5.\n",
      "La similitud entre 'Guijón: Por favor no cambien nunca. Gracias' y 'caro y malo no volveria nunca mas' es 0.25.\n",
      "La similitud entre 'Horrible. Muy mala comida y carísimo.' y 'carisimo, la comida horrible!!!!!!!!!!!!' es 0.816496580927726.\n",
      "La similitud entre 'En los rubros ambiente, atención y comida, lo mejor de Palermo.' y 'mala atencion y falta de buena comida y ambiente, cambien de rubro.' es 0.0.\n"
     ]
    }
   ],
   "source": [
    "lista_comentarios = [\n",
    "    ('muy rica la comida, buenas pizzas', 'excelente pizza la salsa estaba muy rica'),\n",
    "    ('no me gustó para nada. mala atención', 'me pareció todo bastante malo'),\n",
    "    ('que buen servicio, hay que volver', 'excelente todo, me verán seguido por ahí'),\n",
    "    ('las tartas no me gustaron', 'muy bueno servicio'),\n",
    "]\n",
    "\n",
    "lista_comentarios_estudiante = [\n",
    "    ('Es todo muy muy rico y de alta calidad!', 'muy muy rico todo. servicios excellente. buen curry.'),\n",
    "    ('Guijón: Por favor no cambien nunca. Gracias', 'caro y malo no volveria nunca mas'),\n",
    "    ('Horrible. Muy mala comida y carísimo.', 'carisimo, la comida horrible!!!!!!!!!!!!'),\n",
    "    ('En los rubros ambiente, atención y comida, lo mejor de Palermo.', 'mala atencion y falta de buena comida y ambiente, cambien de rubro.')\n",
    "]\n",
    "\n",
    "# COMPLETE A PARTIR DE AQUI\n",
    "for par in lista_comentarios + lista_comentarios_estudiante:\n",
    "    vs = transf_with_stem.transform(par)\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(par[0], par[1], similarity(vs.toarray()[0], vs.toarray()[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroide de vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta parte se representará cada comentario como el centroide de los vectores de las palabras que lo forman. Se pide implementar la función *txt2vec* que dado un comentario y el repertorio de vectores calcula el promedio de los vectores de las palabras del comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2vec(vectores, comentario):\n",
    "    comment_words = nltk.wordpunct_tokenize(comentario.lower())       \n",
    "    vectores_comentario = [getVector(vectores, word) for word in comment_words] \n",
    "            \n",
    "    if (len(vectores_comentario) == 0):\n",
    "        return np.zeros(totalColumnsVectors)\n",
    "    \n",
    "    return np.mean(vectores_comentario, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente la función *data2Xy_vec* cuyo encabezado se presenta en el bloque de código a continuación. La función transforma a los comentarios en su representación de centroide de vectores (las filas de X) y sus etiquetas son las componente del vector y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2Xy_vec(vec, data):        \n",
    "    X = [txt2vec(vec, comentario) for (comentario, etiqueta) in data]\n",
    "    y = [etiqueta for (comentario, etiqueta) in data]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue en pantalla los pares de comentarios de *lista_comentarios* y *lista_comentarios_estudiante* junto con la similitud de sus representaciones de centroide de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre 'muy rica la comida, buenas pizzas' y 'excelente pizza la salsa estaba muy rica' es 0.9032563488394832.\n",
      "La similitud entre 'no me gustó para nada. mala atención' y 'me pareció todo bastante malo' es 0.8814249422516375.\n",
      "La similitud entre 'que buen servicio, hay que volver' y 'excelente todo, me verán seguido por ahí' es 0.8332775016069546.\n",
      "La similitud entre 'las tartas no me gustaron' y 'muy bueno servicio' es 0.6773157715797424.\n",
      "La similitud entre 'Es todo muy muy rico y de alta calidad!' y 'muy muy rico todo. servicios excellente. buen curry.' es 0.877984942326619.\n",
      "La similitud entre 'Guijón: Por favor no cambien nunca. Gracias' y 'caro y malo no volveria nunca mas' es 0.8121591779415548.\n",
      "La similitud entre 'Horrible. Muy mala comida y carísimo.' y 'carisimo, la comida horrible!!!!!!!!!!!!' es 0.867017408240695.\n",
      "La similitud entre 'En los rubros ambiente, atención y comida, lo mejor de Palermo.' y 'mala atencion y falta de buena comida y ambiente, cambien de rubro.' es 0.9233792677637629.\n"
     ]
    }
   ],
   "source": [
    "def similitud_centroides(c1, c2):\n",
    "    centroides_palabras_c1 = txt2vec(vectors, c1)\n",
    "    centroides_palabras_c2 = txt2vec(vectors, c2)\n",
    "    \n",
    "    return similarity(centroides_palabras_c1, centroides_palabras_c2)\n",
    "\n",
    "for c1,c2 in lista_comentarios + lista_comentarios_estudiante:    \n",
    "    similitud_par_comentarios = similitud_centroides(c1, c2)\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(c1, c2, similitud_par_comentarios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comente los resultados de similitud de oraciones obtenidos con las representaciones de bolsa de palabras y las de centroide de vectores.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "En general las similitudes obtenidas con bolsa de palabras son más bajas debido a que solo se miran palabras cuya raíz coincida con la raíz de palabras en el otro comentario, y no necesariamente la similitud (semántica) de dos comentarios implica que se compartan palabras, e incluso comentarios relativamente parecidos dan una similitud de 0.\n",
    "En cambio con centroide de vectores se logra detectar similitudes semánticas más allá de tener o no las mismas palabras, pero a su vez puede suceder que oraciones muy diferentes tengan centroides muy cercanos entre sí debido a meras casualidades que pudieron ocurrir en el corpus con el que se construyeron los vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta sección entrene un clasificador *SVM* de *sklearn* para ambas representaciones (centroide de vectores y bolsa de palabras). Busque una configuración de hiperparámetros adecuada utilizando como referencia el conjunto de validación. Utilice para comparar resultados la medida *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 2.4706937154134114 mins ---\n"
     ]
    }
   ],
   "source": [
    "X,y = data2Xy_bow(transf_with_stem, train)\n",
    "clf = sklearn.svm.LinearSVC(C=22, max_iter=100000)\n",
    "ti = time.time()\n",
    "clf.fit(X, y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9425876324676837\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 8.800824483235677e-05 mins ---\n"
     ]
    }
   ],
   "source": [
    "Xval, yval = data2Xy_bow(transf_with_stem, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(clf.score(Xval, yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 0.2703379432360331 mins ---\n"
     ]
    }
   ],
   "source": [
    "X_centroide_train,y_centroide_train = data2Xy_vec(vectors, train)\n",
    "\n",
    "SVM_centroide = sklearn.svm.LinearSVC(C=22, max_iter=10000)\n",
    "ti = time.time()\n",
    "SVM_centroide.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9559799697216723\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 0.0003843824068705241 mins ---\n"
     ]
    }
   ],
   "source": [
    "X_centroide_val, y_centroide_val = data2Xy_vec(vectors, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(SVM_centroide.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue los resultados obtenidos con *SVM* para ambas representaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierResult(classifier, X, y, modelText):\n",
    "    predicted = classifier.predict(X)\n",
    "    conf = sklearn.metrics.confusion_matrix(y, predicted)\n",
    "    tp, tn, fp, fn = conf[1][1], conf[0][0], conf[0][1], conf[1][0]\n",
    "    print(\"\\nPara el modelo de {} se obtiene lo siguiente:\".format(modelText))\n",
    "    print(\"Hay {} verdaderos positivos, {} verdaderos negativos, {} falsos positivos, {} falsos negativos\".format(tp, tn, fp, fn))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1Score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Precision: {}, recall: {}, Fscore: {}\".format(precision, recall, f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para el modelo de SVM con Bag of Words se obtiene lo siguiente:\n",
      "Hay 5453 verdaderos positivos, 2641 verdaderos negativos, 364 falsos positivos, 129 falsos negativos\n",
      "Precision: 0.937424789410349, recall: 0.9768900035829452, Fscore: 0.9567505921572068\n",
      "\n",
      "Para el modelo de SVM con Centroides se obtiene lo siguiente:\n",
      "Hay 5437 verdaderos positivos, 2772 verdaderos negativos, 233 falsos positivos, 145 falsos negativos\n",
      "Precision: 0.9589065255731922, recall: 0.9740236474381943, Fscore: 0.9664059722715962\n"
     ]
    }
   ],
   "source": [
    "printClassifierResult(clf, Xval, yval, \"SVM con Bag of Words\")\n",
    "printClassifierResult(SVM_centroide, X_centroide_val, y_centroide_val, \"SVM con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Fowrward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta sección utilizará un clasificador de red neuronal *feed forward* (*multilayer perceptron* - MLP) para realizar la clasificación de sentimiento de los comentarios considerando ambas representaciones: centroide de vectores y bolsa de palabras. Busque una configuración de hiperparámetros adecuada tomando como referencia la medida de *accuracy* obtenida en el conjunto de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 0.06974427700042725 mins ---\n",
      "\n",
      "Accuracy: 0.9430534528939094\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 0.00015703439712524414 mins ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clfNN = MLPClassifier(solver='adam', alpha=1e-5, batch_size=500, max_iter=500, learning_rate='adaptive', hidden_layer_sizes=(5, 2), shuffle=False, activation='identity', tol=1e-4)\n",
    "ti = time.time()\n",
    "clfNN.fit(X,y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)\n",
    "\n",
    "ti = time.time()\n",
    "print(\"\\nAccuracy: \" + str(clfNN.score(Xval,yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 0.5119045337041219 mins ---\n",
      "\n",
      "Accuracy: 0.9529521369512053\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 0.0005107919375101725 mins ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_centroide = MLPClassifier(solver='adam', alpha=1e-10, batch_size=500, max_iter=500, learning_rate='adaptive', hidden_layer_sizes=(5, 2), shuffle=False, activation='identity', tol=1e-4)\n",
    "ti = time.time()\n",
    "NN_centroide.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)\n",
    "\n",
    "ti = time.time()\n",
    "print(\"\\nAccuracy: \" + str(NN_centroide.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue los mejores resultados obtenidos para ambas representaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para el modelo de Feed Forward Neural Network con Bag of Words se obtiene lo siguiente:\n",
      "Hay 5440 verdaderos positivos, 2658 verdaderos negativos, 347 falsos positivos, 142 falsos negativos\n",
      "Precision: 0.940038016243304, recall: 0.974561089215335, Fscore: 0.9569883015216817\n",
      "\n",
      "Para el modelo de Feed Forward Neural Network con Centroides se obtiene lo siguiente:\n",
      "Hay 5490 verdaderos positivos, 2693 verdaderos negativos, 312 falsos positivos, 92 falsos negativos\n",
      "Precision: 0.9462254395036195, recall: 0.9835184521676819, Fscore: 0.9645115952213633\n"
     ]
    }
   ],
   "source": [
    "printClassifierResult(clfNN, Xval, yval, \"Feed Forward Neural Network con Bag of Words\")\n",
    "printClassifierResult(NN_centroide, X_centroide_val, y_centroide_val, \"Feed Forward Neural Network con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores Resultados en Validación\n",
    "\n",
    "Analice los resultados obtenidos con cada clasificador y cada representación en el conjunto de validación. \n",
    "\n",
    "Tenga en cuenta que debe considerar al menos los siguientes 4 clasificadores:\n",
    "\n",
    "- SVM con BOW\n",
    "- SVM con Centroide\n",
    "- MLP con BOW\n",
    "- MLP con Centroide\n",
    "\n",
    "Realice los comentarios que considere adecuados respecto a la comparación y resultados obtenidos. Si lo desea puede agregar bloques de código que muestren resultados adicionales.\n",
    "\n",
    "**Respuesta:** \n",
    "###### SVM:\n",
    "\n",
    "En el caso de SVM, se probaron dos implementaciones del clasificador SVM: LinearSVC y SVC. En cuanto a la comparación entre resultados obtenidos, son similares en las dos implementaciones. LinearSVC se comportó mejor utilizando la representación de centroides y en el caso de SVC se obtuvo una pequeña mejora utilizando la representación de bolsa de palabras. En relación a la performance computacional, la segunda resulta demorar menos. Esto puede suceder por las diferencias de implementación entre las dos funcionalidades o por desactivar el shrinking para mejorar los resultados (lo cual cuando se activa mejora los tiempos). \n",
    "\n",
    "Respecto a la comparación entre los resultados obtenidos para las dos representaciones vectoriales de palabras, si tomamos el valor F (_Fscore_) como medida de correctitud general, se ve que el clasificador SVM con representación de centroide mejora levemente al clasificador SVM con representación de bolsa de palabras. Esto puede deberse a que la representación de centroides recoge aspectos estadísticos a un nivel más global que el caso de bag of words, para la cual se consideran menos palabras.\n",
    "El otro aspecto a evaluar es que se percibe una mejora significativa en el tiempo de entrenamiento y validación para el caso en que se utiliza la representación de centroides. Esto puede suceder debido a que los vectores de dicha representación tienen una menor cantidad de features que los que se obtienen utilizando la representación de bolsa de palabras (300 en representación de centroides, 486 en bolsa de palabras).\n",
    "\n",
    "###### MLP:\n",
    "\n",
    "En el caso de MLP, se probó una única implementación, MLPClassifier. Vemos que al igual que con LinearSVC, la representación de centroides mejora la precision de la red neuronal y mantiene un recall relativamente parecido a cuando se utiliza la representación de bolsa de palabras. Se ajustó el parámetro alfa de regularización de tal forma que se produjeran los mejores resultados para cada representación. Esta puede ser una de las razones, además de las mencionadas antes, por la cual se da una diferencia en el tiempo de ejecución requerido para entrenar cada clasificador, ya que cuanto menor es alfa más se intenta ajustar la función.\n",
    "\n",
    "###### SVM vs. MLP:\n",
    "\n",
    "El primer factor que salta a la vista es la diferencia de performance de tiempo computacional. El clasificador que utiliza la red neuronal posee una amplia mejora (tanto en tiempo de entrenamiento como de validación) con respecto a los dos clasificadores que utilizan SVM.\n",
    "\n",
    "Prosiguiendo con los resultados en la validación se puede ver que en el caso del clasificador MLP, presenta un valor F similar al clasificador SVM para el caso de la representación con centroides (considerando la implementación LinearSVC), y apenas menor para el caso de la representación de bolsa de palabras (considerando la implementación SVC).\n",
    "\n",
    "Yendo a los resultados más concretos, el clasificador LinearSVC obtiene los mejores valores con respecto a la cantidad de ejemplos clasificados correctamente. En relación a los ejemplos clasificados incorrectamente, se obtienen resultados mixtos: el clasificador MLP empeora la cantidad de falsos positivos en relación con LinearSVC (no así con SVC) cuando se utiliza la representación de centroides, pero reduce la cantidad de falsos negativos en relación a las 2 implementaciones. Para el caso de la representación de comentarios con bolsa de palabras, MLP empeora la cantidad de falsos negativos y en cuanto a los falsos positivos, se obtiene el mejor resultado para SVC, seguido por el clasificador MLP y, por último, el clasificador LinearSVC.\n",
    "\n",
    "Podemos ver estos resultados proyectados en una **precision** máxima obtenida para LinearSVC con centroides (y con un poco menos MLP con centroides) debido a la alta cantidad de ejemplos clasificados correctamente. En cuanto a la **recall**, la máxima se obtuvo para MLP con centroides. Esto nos indica que los mejores resultados se obtuvieron con LinearSVC y MLP, ambos utilizando la representación con centroides.\n",
    "\n",
    "Podemos concluir entonces que, para el corpus de comentarios, aunque los dos clasificadores (y las dos implementaciones del clasificador SVM) arrojan resultados similares para ambas representaciones de comentarios, el clasificador MLP presenta una mejora en cuanto a tiempo computacional y en la calidad de resultados en general que puede inclinar la balanza a su favor.\n",
    "\n",
    "**Clasificador SVM implementado en SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 3.6378072023391725 mins ---\n"
     ]
    }
   ],
   "source": [
    "X,y = data2Xy_bow(transf_with_stem, train)\n",
    "clf2 = sklearn.svm.SVC(kernel='linear',shrinking=False)\n",
    "ti = time.time()\n",
    "clf2.fit(X, y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9446838243856993\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 0.08876012563705445 mins ---\n"
     ]
    }
   ],
   "source": [
    "Xval, yval = data2Xy_bow(transf_with_stem, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(clf2.score(Xval, yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: \n",
      "\n",
      "--- 2.4220492164293925 mins ---\n"
     ]
    }
   ],
   "source": [
    "X_centroide_train,y_centroide_train = data2Xy_vec(vectors, train)\n",
    "\n",
    "SVM_centroide2 = sklearn.svm.SVC(kernel='linear',shrinking=False)\n",
    "ti = time.time()\n",
    "SVM_centroide2.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9470129265168278\n",
      "Tiempo de validación: \n",
      "\n",
      "--- 0.5272740046183269 mins ---\n"
     ]
    }
   ],
   "source": [
    "X_centroide_val, y_centroide_val = data2Xy_vec(vectors, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(SVM_centroide2.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierResult(classifier, X, y, modelText):\n",
    "    predicted = classifier.predict(X)\n",
    "    conf = sklearn.metrics.confusion_matrix(y, predicted)\n",
    "    tp, tn, fp, fn = conf[1][1], conf[0][0], conf[0][1], conf[1][0]\n",
    "    print(\"\\nPara el modelo de {} se obtiene lo siguiente:\".format(modelText))\n",
    "    print(\"Hay {} verdaderos positivos, {} verdaderos negativos, {} falsos positivos, {} falsos negativos\".format(tp, tn, fp, fn))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1Score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Precision: {}, recall: {}, Fscore: {}\".format(precision, recall, f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para el modelo de SVM con Bag of Words se obtiene lo siguiente:\n",
      "Hay 5448 verdaderos positivos, 2664 verdaderos negativos, 341 falsos positivos, 134 falsos negativos\n",
      "Precision: 0.9410951805147694, recall: 0.9759942672877105, Fscore: 0.9582270688593792\n",
      "\n",
      "Para el modelo de SVM con Centroides se obtiene lo siguiente:\n",
      "Hay 5404 verdaderos positivos, 2728 verdaderos negativos, 277 falsos positivos, 178 falsos negativos\n",
      "Precision: 0.9512409787009329, recall: 0.9681117878896452, Fscore: 0.9596022374145433\n"
     ]
    }
   ],
   "source": [
    "printClassifierResult(clf2, Xval, yval, \"SVM con Bag of Words\")\n",
    "printClassifierResult(SVM_centroide2, X_centroide_val, y_centroide_val, \"SVM con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall y Matriz de Confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule la medida de *accuracy* en el conjunto de *test* para los modelos de la parte anterior. Despliegue los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM bow tiene accuracy 0.9466195977749251 para el conjunto de test\n",
      "FF NN bow tiene accuracy 0.9473684210526315 para el conjunto de test\n",
      "SVM centroide tiene accuracy 0.9603123662815576 para el conjunto de test\n",
      "FF NN centroide tiene accuracy 0.9567821994009413 para el conjunto de test\n"
     ]
    }
   ],
   "source": [
    "Xtest, ytest = data2Xy_bow(transf_with_stem, test)\n",
    "X_centroide_test,y_centroide_test = data2Xy_vec(vectors, test)\n",
    "\n",
    "print(\"SVM bow tiene accuracy {} para el conjunto de test\".format(clf.score(Xtest, ytest)))\n",
    "print(\"FF NN bow tiene accuracy {} para el conjunto de test\".format(clfNN.score(Xtest, ytest)))\n",
    "print(\"SVM centroide tiene accuracy {} para el conjunto de test\".format(SVM_centroide.score(X_centroide_test, y_centroide_test)))\n",
    "print(\"FF NN centroide tiene accuracy {} para el conjunto de test\".format(NN_centroide.score(X_centroide_test, y_centroide_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Seleccione uno de los modelos y analice sus errores en función de la matriz de confusión. Compute las medidas de *precision*, *recall* y *F*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para el modelo de Feed Forward Neural Network con Bag of Words se obtiene lo siguiente:\n",
      "Hay 5972 verdaderos positivos, 2884 verdaderos negativos, 352 falsos positivos, 140 falsos negativos\n",
      "Precision: 0.9443390259329538, recall: 0.9770942408376964, Fscore: 0.9604374396912191\n"
     ]
    }
   ],
   "source": [
    "printClassifierResult(clfNN, Xtest, ytest, \"Feed Forward Neural Network con Bag of Words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue algunos casos de falsos positivos y falsos negativos del clasificador seleccionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Falsos positivos #########\n",
      "\n",
      "('Increiblemente fui con expectativas que me crearon seguidores de este restaurante y la verdad no fueron superadas. Probe llama, ñandu y yacaré y a las tres carnes les faltaba sabor; las presentaciones (?). El servicio flojo. Y sobre la ambientacion no me gusto, es una mezcla de \"restaurante\" y \"almacen\" quizas asi se refleja que no es ni una cosa ni la otra.', 'NEG')\n",
      "('El lugar es muy lindo y la música también, pero la comida no tanto... comimos unos tacos de carne y de pescado, los primeros zafaban, pero los segundos casi no tenían pescado... cuando preguntamos por los postres, nos dijeron que tenían muchos pedidos en la cocina ¿? En resumen, para pasar un buen rato está bien, pero no me gustaron los tacos.', 'NEG')\n",
      "('Somo italianos y la verdad que preferimos la pizza Napoletana en serio, como la de Siamo nel Forno por ejemplo, pero este lugar nos encantò, muy muy lindo. La calidad deja muchas dudas, la atenciòn ni hablar, muy ruidoso tambien cuando se llena, pero el ambiente es espetacular, de esos lugares donde sacarse una foto significa crear una postal de un lugar rapresentativo de la comida portena. Bastante caro por la calidad de los productos que usan, muzzarella X...pero no importa, vale la pena ir, muy buena experiencia.', 'NEG')\n",
      "('fui con una amiga el lunes 30/04. El local tiene mucha onda, como el de palermo hollywood. Esta vez la comida no me convencio. Sandwich de lomo poca carne ylimonada con jengibre muy dulce.', 'NEG')\n",
      "('La atención es muy descuidada.. la comida es mediocre y la ambientación con muy poca clase. Lo único rescatable es la limonada, pero siendo una zona tan linda es inaceptable un lugar asi', 'NEG')\n",
      "('Soy amante de la comida venzolana  y por eso lleve a  unos amigos para que conozcan las comida tipica  y relamente fue una gran decepcion.\\r\\nLos tequeños estaban congelados y las arepas se dearmaban todas con trozoa de polenta. \\r\\nRealmente no lo recomiendo.', 'NEG')\n",
      "(\"I've been to several italian restaurants in south america and none even come close to even a mediocre italian place back home. First off, the lasagna was burnt and the red sauce had absolutely no spice added. To add insult to injury, the pastry part of the cannoli was burnt. The menus are stained and the place is pretty shabby. I thought many argentines come from an italian background, what happened?\", 'NEG')\n",
      "('Fuimos con un Groupon y la comida no era la gran cosa, todo muy simple, y poco. Muy lindo el lugar, re bien decorado. Habría que probarlo sin cupon, porque sino no lo recomiendo.', 'NEG')\n",
      "('pedi rabas y me dieron unas \"bolas de fraile llenas de tentaculos\" !!! saquen sus conclusiones!', 'NEG')\n",
      "('Muy lindo el lugar. Riquísima su version de la chocotorta. Solo que la cocina muy demorada. El sandwich de salmon era minimo y las papas tenian sabor a pescado. Los mozos amorosos y cordiales. El cafe muy rico igual que el agua de frambuesa. Ir con paciencia, porque la cocina tarrrda!', 'NEG')\n",
      "\n",
      "######### Falsos negativos #########\n",
      "\n",
      "('fui  a cenar por  cupon de pez urbano, sin postre.\\r\\n lo compre antes de leer los comentarios\\r\\nMenos mal.!\\r\\n No hay mal que por bien no venga:\\r\\nEl lugar es un barcito pintoresco, con mesas dentro y fuera del local.\\r\\nEl ambiente, es un ambiente fresco de juventud y algunos son del extranjero, linda música de rock(la renga)\\r\\nEl mozo, un personaje \" bogoteño\", simpático y de los mas amable.\\r\\nNos atendio en un tiempo normal y la pizza era muy rica.\\r\\nPor lo tanto no estoy de acuerdo con los anteriores comentarios y  contenta de no haberlos leído antes de comprar el cupon!!!!!', 'POS')\n",
      "('La decoración es divina. Se presta para una salida con amigas o en pareja. las mesas tienen un plush debajo que absoreve el audio por lo que no es ruidoso para nada. Las opciones del menú son variadas para para los amantes del bueno comer. Volvería.', 'POS')\n",
      "('Fuimos el sábado 7 de julio todo muy bueno desde la atención permanente de todas las mozas hasta la calidad de la comida y la relación precio calidad, seguramente volveremos!! Unica objeción las ventanas no tienen cortinas, fuimos un día súper frío y tuvimos que cambiarnos de mesa por el frio q filtraba; para tener en cuenta!', 'POS')\n",
      "('Una propuesta resuelta con excelencia en la calidad y la atención de cómo es actualmente un bar/almacén/bistró de barrio versión 2011 de lo que antaño sería una pulpería/bar de copetin con picadas, vermouth y tres platos calientes. Para volver cada día los que vivimos en el barrio.', 'POS')\n",
      "('Es ideal para desayunar o merendar. Recomiendo aprovechar las promociones que tiene el lugar. El lugar es chico y tranquilo. Es ruidoso por los medios de transportes nada mas.', 'POS')\n",
      "('Fuimos con un amigo a probar de qué se trata y la sorpresa fue total.  La experiencia se podría resumir como un viaje condensado a Italia y a New York al mismo tiempo.\\r\\nSabés de qué se trata y te gusta? entonces este es tu lugar: mesitas chiquitas, cocina integrada al salón, todo se hace cuando lo pedís, los ingredientes son de lo mejor; y Donato y su esposa te hacen sentir como en casa.\\r\\nLa espera fue larga y parados afuera, pero valió la pena.\\r\\nAdemás, después de un rato de esperar, pedimos si por favor nos preparaban algo de picar, lo que ellos quisieran:en vez de restar, sumó.  Voy a volver!', 'POS')\n",
      "('Muy buen lugar, el ambiente y la atencion son excelentes. Ademas tanto la pizza como la comida de 10. Yo pedi milanesa con papas fritas y fue muy liviana, con poca aceite, bien hecha. Otro dia pedi Pizza y estubo muy bien.\\r\\nEl precio normal.', 'POS')\n",
      "('Comimos una Pizza de Champignones, y tomamos unas cervezas, estaba espectacular. Para nada caro, el ambiente y la atención es de lo mejor de Canitas y lo bueno es que despues nos quedamos a tomar algo y tienen muy buenos tragos, recomendación: el mojito.', 'POS')\n",
      "('Fuimos anoche, sin tener experiencia en la comida india.  Nos gustó, la atención buena, la comida muy bien hecha con platos abundantísimos, en fin absolutamente recomendable. Las falencias que tienen son facilmente subsanables, por ejemplo poner bien la mesa, no apilar los cubiertos, agregar vinos a la carta, era muy pequeña, pero eso es porque son jóvenes y hace poco se instalaron.  Creo que van a tener exito.  Hago la aclaración que entre dos con vino y un agua gastamos $ 130.- con un cupón de descuento.', 'POS')\n",
      "('fui con un compañero de trabajo a comer, comimos un pollo agridulce con castañas de caju y anana, excelente, la atencion muy buena y muy economico el menu del medio dia, vuelvo seguro pero de noche.. ah me olvidaba el lugar chiquito pero muy lindo', 'POS')\n"
     ]
    }
   ],
   "source": [
    "predicted = clfNN.predict(Xtest)\n",
    "\n",
    "print(\"######### Falsos positivos #########\\n\")\n",
    "\n",
    "# falsos positivos\n",
    "total_fp_printed = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 'POS' and predicted[i] != ytest[i]:\n",
    "        print(test[i])\n",
    "        total_fp_printed += 1\n",
    "    if total_fp_printed == 10: \n",
    "        break;\n",
    "        \n",
    "print(\"\\n######### Falsos negativos #########\\n\")\n",
    "\n",
    "# falsos negativos\n",
    "total_fn_printed = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 'NEG' and predicted[i] != ytest[i]:\n",
    "        print(test[i])\n",
    "        total_fn_printed += 1\n",
    "    if total_fn_printed == 10: \n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar con detenimiento los falsos positivos y los falsos negativos, se puede ver en términos generales que los mismos son un tanto neutros, es decir, comentarios que tienen en su contenido una mención positiva, pero que al mismo tiempo como contraste hacen notar una característica negativa, creemos que es por esta razón que se clasificaron incorrecamente por el modelo elegido. \n",
    "\n",
    "Para una ejecución en particular -notar que solo imprimimos 20 *falsos* sin un orden preestablecido-, tomamos algunos comentarios para ejemplificar lo que mencionamos:\n",
    "\n",
    "*('Excelente ambiente. El menu no tiene relación con el lugar. Caro y pretensioso.', 'NEG')*\n",
    "- **Aspecto positivo:** el ambiente\n",
    "- **Aspecto negativo:** el precio\n",
    "\n",
    "Si tuvieramos que clasificarlo lo haríamos negativo porque tiene dos oraciones negativas contra una positiva, y la palabra caro es muy negativa en estos casos, pesando más que el lugar en si mismo.\n",
    "\n",
    "*('El lugar está bien ambientado y al principio todos son muy amables. Fuimos a disfrutar del premio #mesadeamigos de guia oleo y casi se nos frustra el festejo por una falta de comunicación entre la gente del lugar. Solucionado el problema todo bien. Yo pedí un bife de chorizo y la carne estaba roja por dentro y quemada por fuera... las carnes no son lo más recomendable. Sí los postres que son muy ricos.', 'NEG')*\n",
    "- **Aspecto positivo:** ambiente, amabilidad, los postres\n",
    "- **Aspecto negativo:** falta de comunicación, mala cocción y calidad de las carnes\n",
    "\n",
    "Es un comentario neutro a nuestro entender, dado que el festejo no salió frustrado finalmente, y hubo apenas un problema en la cocción de la carne.\n",
    "\n",
    "*('el lugar excelente. un poquito lento el plato principal de sushi pero realmente excelente un abrazo a todos con el descuento de GO pagamos 180 por persona', 'POS')*\n",
    "- **Aspecto positivo**: el lugar, el descuento\n",
    "- **Aspecto negativo**: lento el plato principal\n",
    "\n",
    "Claramente un comentario positivo, suponemos que la palabra lento sucede en muchos comentarios anotados negativamente y eso hizo pesar en la predicción.\n",
    "\n",
    "*('Muy buen ambiente, moderno y con buen gusto. Fuimos el jueves 23 a las 20.15 y no habia demasiada gente, quizas tardaron en servir los platos pero la amabilidad estuvo bien.', 'POS')*\n",
    "- **Aspecto positivo**: ambiente, amabilidad\n",
    "- **Aspecto negativo**: demora habiendo poca gente\n",
    "\n",
    "Nuevamente un comentario positivo a nuestro entender, quizá la palabra *tardaron* debe ser una palabra con mucho peso negativo en este contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo de oraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Utilice cada uno de los clasificadores considerados anteriormente para cada comentario de *lista_comentarios* y *lista_comentarios_estudiante*.\n",
    "\n",
    "Despliegue en pantalla cada comentario junto con la salida obtenida por cada clasificador. Realice los comentarios que considere pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'muy rica la comida, buenas pizzas' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'excelente pizza la salsa estaba muy rica' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'no me gustó para nada. mala atención' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'me pareció todo bastante malo' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'que buen servicio, hay que volver' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'excelente todo, me verán seguido por ahí' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'las tartas no me gustaron' fue clasificado como: \n",
      "'POS', 'POS', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'muy bueno servicio' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'Es todo muy muy rico y de alta calidad!' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'muy muy rico todo. servicios excellente. buen curry.' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'Guijón: Por favor no cambien nunca. Gracias' fue clasificado como: \n",
      "'NEG', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'caro y malo no volveria nunca mas' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'Horrible. Muy mala comida y carísimo.' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'carisimo, la comida horrible!!!!!!!!!!!!' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'En los rubros ambiente, atención y comida, lo mejor de Palermo.' fue clasificado como: \n",
      "'POS', 'POS', 'POS', 'POS' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n",
      "\n",
      "'mala atencion y falta de buena comida y ambiente, cambien de rubro.' fue clasificado como: \n",
      "'NEG', 'NEG', 'NEG', 'NEG' \n",
      "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\n"
     ]
    }
   ],
   "source": [
    "comentarios = [y for x in ([c1, c2] for c1,c2 in lista_comentarios + lista_comentarios_estudiante) for y in x]\n",
    "\n",
    "for comentario in comentarios:\n",
    "    X_comment = transf_with_stem.transform([comentario])\n",
    "    X_centroide = txt2vec(vectors, comentario)\n",
    "    print()\n",
    "    print(\"'{}' fue clasificado como: \\n'{}', '{}', '{}', '{}' \\npara BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\".format(comentario, clfNN.predict(X_comment)[0], clf.predict(X_comment)[0], NN_centroide.predict([X_centroide])[0], SVM_centroide.predict([X_centroide])[0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 16 comentarios clasificados, en 14 de ellos los cuatro modelos coincideron en la clasificación. Es decir que solo hubo disconcordancia en el 13% de los comentarios (2 de 16).\n",
    "\n",
    "Creemos que la clasificación para los 14 comentarios es correcta, dado que en ellos hay una clara connotación ya sea negativa o positiva pero no ambas a la vez, es decir, no los consideramos comentarios neutros.\n",
    "\n",
    "Por otro lado observamos los comentarios para los cuales no hubo unanimidad en su clasificación:\n",
    "\n",
    "**'las tartas no me gustaron' fue clasificado como: \n",
    "'POS', 'POS', 'NEG', 'NEG' \n",
    "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente**\n",
    "\n",
    "A nuestro entender el comentario es claro y conciso, definitivamente negativo. Dado esto, los modelos que usaron centroide de vectores acertaron, mientras que los modelos que usaron representación BOW fallaron en su clasificación.\n",
    "\n",
    "Notar que para este caso *gustaron* y en particular su stem *gust* es la característica que se utilizó para clasificar. Notar que la palabra *no* revierte la connotación que tiene el stem gust, sin embargo no es considerada para la clasificación, ya que no se encuentra en el vocabulario, seguramente por haber sido filtrada al utilizar los parametros max_df y min_df.\n",
    "\n",
    "**'Guijón: Por favor no cambien nunca. Gracias' fue clasificado como: \n",
    "'NEG', 'POS', 'POS', 'POS' \n",
    "para BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente**\n",
    "\n",
    "Nuevamente el comentario es claramente positivo, los modelos con representación de centroide nuevamente clasificaron correctamente, pero esta vez solo falló la red neuronal utilizando representación BOW.\n",
    "\n",
    "A diferencia con el comentario anterior, la mala clasificación radica en el modelo en si mismo y no tanto en la   representación vectorial utilizada.\n",
    "\n",
    "Creemos que en ambos casos la representación de centroides se ve favorecida en que sus vectores tienen mayor información ya que tienen contenido en si mismo el contexto (por utilizar vectores de palabras), lo cual hace que los vectores resultantes de cada comentario sean más representativos aportando mayor información sobre el tipo de contenido del mismo. Por otro lado, el modelo BOW solo tiene en cuenta la cantidad de ocurrencias de las palabras en un documento sobre un vocabulario conocido, creemos que en comentarios relativamente cortos y con palabras nuevas dentro del vocabulario, no contendran la suficiente información para poder clasificarlos correctamente. Esto no hace más que reconfirmar los resultados obtenidos en secciones anteriores, donde el F1 score fue mejor para los modelos que usaron representación de centroides."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
