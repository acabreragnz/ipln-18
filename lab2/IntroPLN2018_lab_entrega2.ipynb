{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Introducción al Procesamiento del Lenguaje Natural 2018 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *notebook* de Python contiene las instrucciones para la segunda entrega del curso Introducción al Procesamiento de Lenguaje Natural. En el mismo se encontrará con instrucciones en bloques de texto y bloques de código para completar. Si bien no debe modificar la estructura base del notebook, puede agregar los bloques de texto o código que considere pertinentes para aportar claridad a la entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que su entorno de Python 3 contiene todas las bibliotecas necesarias. Ejecute el bloque código a continuación para importar las bibliotecas nltk, sklearn y otras que le serán de utilidad. Verifique que se importan sin errores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import os \n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe el corpus contenido en el directorio *restaurante-review-dataset* extraído de [1]. Note la partición en entrenamiento (train), validación (val) y evaluación (test). Ejecute el bloque a continuación para cargar el contenido del corpus en tres variable: *train*, *validation* y *test*. Se utiliza como estructura de datos una lista de pares (comentario, valor), donde comentario es una string con el comentario y valor corresponde a la string \"POS\" o \"NEG\" si el comentario es positivo o negativo, respectivamente.\n",
    " \n",
    "[1] Dubiau, L., & Ale, J. M. (2013). Análisis de Sentimientos sobre un Corpus en Español: Experimentación con un Caso de Estudio. In Proceedings of the 14th Argentine Symposium on Artificial Intelligence, ASAI (pp. 36-47).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, val):\n",
    "    data = []\n",
    "    for file in os.listdir(directory):\n",
    "        with open(os.path.join(directory, file)) as f:\n",
    "            file_data = json.load(f)\n",
    "            data += [(l,val) for l in file_data]\n",
    "    return data\n",
    "\n",
    "corpus_train_dirs = [\n",
    "    (\"./restaurante-review-dataset/train-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/train-pos/\", \"POS\"),\n",
    "]\n",
    "corpus_val_dirs = [\n",
    "    (\"./restaurante-review-dataset/val-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/val-pos/\", \"POS\"),\n",
    "]\n",
    "corpus_test_dirs = [\n",
    "    (\"./restaurante-review-dataset/test-neg/\", \"NEG\"),\n",
    "    (\"./restaurante-review-dataset/test-pos/\", \"POS\"),\n",
    "]\n",
    "\n",
    "train, validation, test = [],[],[]\n",
    "for d,v in corpus_train_dirs:\n",
    "    train += load_data(d, v)\n",
    "for d,v in corpus_val_dirs:\n",
    "    validation += load_data(d, v)\n",
    "for d,v in corpus_test_dirs:\n",
    "    test += load_data(d, v)\n",
    "\n",
    "random.Random(1234).shuffle(train)\n",
    "random.Random(2345).shuffle(validation)\n",
    "random.Random(3456).shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue en pantalla la cantidad de elementos positivos, negativos y totales de cada partición del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPOS = sum(1 for comentario in train if comentario[1] == 'POS')\n",
    "trainTOT = len(train)\n",
    "trainNEG = trainTOT - trainPOS\n",
    "\n",
    "validationPOS = sum(1 for comentario in validation if comentario[1] == 'POS')\n",
    "validationTOT = len(validation)\n",
    "validationNEG = validationTOT - validationPOS\n",
    "\n",
    "testPOS = sum(1 for comentario in test if comentario[1] == 'POS')\n",
    "testTOT = len(test)\n",
    "testNEG = testTOT - testPOS\n",
    "\n",
    "print(\"En la partición 'train' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(trainTOT, trainPOS, trainNEG))\n",
    "print(\"En la partición 'validation' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(validationTOT, validationPOS, validationNEG))\n",
    "print(\"En la partición 'test' hay un total de {} comentarios de los cuales {} son positivos y {} son negativos.\\n\".format(testTOT, testPOS, testNEG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los *word vectors* son representaciones vectoriales de las palabras construidas a partir de grandes colecciones de texto. Junto a este *notebook* se imparte un reportorio de vectores construido a partir de un corpus en español usando *skip-gram* con *negative sampling* (SGNS)[1]\n",
    "\n",
    "En esta sección cargará en memoria y utilizará el repertorio de vectores impartido. Además, se evaluará la cobertura del repertorio en el corpus y se estudiará las palabras del corpus no contempladas en el repertorio de vectores (*out-of-vocabulary terms*).\n",
    "\n",
    "En el directorio *vectores* se encuentran dos archivos:\n",
    "\n",
    "- sgns_spvectors_300.txt con la lista de palabras del repertorio\n",
    "- sgns_spvectors_300.npy con la matriz que contiene cada vector\n",
    "\n",
    "Defina un mecanismo para cargar en memoria los vectores y para obtener en tiempo eficiente el vector correspondiente a una palabra. Tenga en cuenta lo siguiente:\n",
    "\n",
    "- puede serle útil un diccionario que a cada palabra le corresponda su índice en la matriz\n",
    "- resuelva que hacer con las palabras que no están en el repertorio de vectores\n",
    "\n",
    "\n",
    "[1] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vectors = np.load('./vectores/sgns_spvectors_300.npy')\n",
    "\n",
    "with open('./vectores/sgns_spvectors_300.txt', 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "_, totalColumnsVectors = vectors.shape\n",
    "\n",
    "numToWord = dict(list(enumerate(words)))\n",
    "wordToNum = {v: k for k, v in numToWord.items()}\n",
    "\n",
    "def getVector(vectors, word):\n",
    "    try:\n",
    "        vec = vectors[wordToNum[word]]\n",
    "    except KeyError:\n",
    "        return [0 for _ in range(totalColumnsVectors)]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realice pruebas con los vectores almacenados. En el siguiente bloque de código realice lo siguiente:\n",
    "\n",
    "1. Defina una función de similitud entre vectores\n",
    "2. Imprima la similitud entre los vectores de las palabras de ejemplo\n",
    "3. Defina un conjunto de pares de palabras del repertorio de vectores (*pares_estudiante*)\n",
    "4. Imprima la similitud de los vectores de las palabras definidas en el paso anterior\n",
    "5. Imprima el vector correspondiente a una palabra que no se encuentre en el repertorio de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def similarity(vector1, vector2):\n",
    "    if ((norm(vector1) == 0) or (norm(vector2) == 0)):\n",
    "        return 0\n",
    "    return 1 - cosine(vector1, vector2)\n",
    "\n",
    "pares = [\n",
    "    ('bueno','excelente'),\n",
    "    ('bueno','buena'),\n",
    "    ('bueno','malo'),\n",
    "    ('malo','espantoso'),\n",
    "    ('comida', 'ambiente'),\n",
    "    ('comida', 'bebida'),\n",
    "    ('comida', 'postre'),\n",
    "    ('comida', 'sabor'),\n",
    "    ('servicio', 'comida'),\n",
    "    ('servicio', 'ambiente'),\n",
    "    ('ambiente', 'calor'),\n",
    "    ('frío', 'calor'),\n",
    "]\n",
    "\n",
    "print(\"Conjunto 'pares':\\n\")\n",
    "\n",
    "for pair in pares:\n",
    "    vector0 = getVector(vectors, pair[0])\n",
    "    vector1 = getVector(vectors, pair[1])\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(pair[0], pair[1], similarity(vector0, vector1)))\n",
    "\n",
    "print(\"\\nConjunto 'pares_estudiante':\\n\")\n",
    "\n",
    "pares_estudiante = [\n",
    "    ('bodka', 'vodka'),\n",
    "    ('manuela', 'marea'),\n",
    "    ('salado', 'dulce'),\n",
    "    ('rico', 'sabroso'),\n",
    "    ('agua', 'salada'),\n",
    "    ('postre', 'dulce'),\n",
    "    ('ambiente', 'agradable'),\n",
    "    ('tecnologia', 'idem'),\n",
    "    ('pista', 'carreras'),\n",
    "    ('administración', 'empresas'),\n",
    "    ('anterior', 'posterior'),\n",
    "    ('buenos', 'aires'),\n",
    "    ('francia', 'españa'),\n",
    "    ('francia', 'espana'),\n",
    "    ('france', 'spain'),\n",
    "    ('alejandro', 'magno'),\n",
    "    ('año', 'nuevo'),\n",
    "    ('caño', 'caños'),\n",
    "    ('el', 'la'),\n",
    "    ('eso', 'esa'),\n",
    "] \n",
    "\n",
    "for pair in pares_estudiante:\n",
    "    vector0 = getVector(vectors, pair[0])\n",
    "    vector1 = getVector(vectors, pair[1])\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(pair[0], pair[1], similarity(vector0, vector1)))\n",
    "    \n",
    "print(\"\\nEl vector correspondiente a una palabra que no se encuentre en el repertorio de vectores es: \\n\", getVector(vectors, 'palabrafueradelrepertorio'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué observa en los resultados obtenidos?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Para analizar los resultados obtenidos debemos tener en cuenta el funcionamiento del modelo skip-gram. Dicho modelo obtiene los vectores al entrenar una red neuronal que tiene como entrada un vector 'one-hot' (esto es, un vector de largo _n = cantidad de tokens en el corpus_ y con valor 1 en la posición que corresponde a la palabra ingresada y 0 en los demás valores) que representa una palabra, devolviendo como salida un vector de probabilidades de que cada palabra del corpus de entrenamiento se encuentre en el contexto de la palabra ingresada (o sea, en su proximidad). Luego, los vectores se obtienen de la matriz resultante en la capa oculta de la red. Este modelo es forma parte del conjunto de modelos _word2vec_.\n",
    "De este modelo se deriva que la distancia entre dos palabras en su representación vectorial nos permite obtener una medida de si una de ellas aparece en el mismo contexto que la otra en nuestro corpus de entrenamiento.\n",
    "\n",
    "Es así que podemos observar, por ejemplo, que las palabras 'bueno' y 'malo' aparecen en el mismo contexto varias veces ya que tienen un valor de similitud alto. Lo mismo ocurre con palabras como 'frío' y 'calor', 'francia' y 'españa' mientras que palabras como 'manuela' y 'marea' no aparecen prácticamente nunca en el mismo contexto. Las palabras 'buenos' y 'aires' son de las que mayor valor de similitud tienen, ya que suelen aparecer juntas conformando un nombre propio. Parece ser que no se hizo en este caso, pero en [1] recomiendan tratar este tipo de \"frases\" como una palabra en sí, manteniendo separado el significado de las palabras cuando se encuentran aparte de cuando se encuentran juntas.\n",
    "También podemos ver que pronombres con el mismo significado pero que varían en género tienen una similitud muy alta.\n",
    "\n",
    "Por último, cabe destacar ciertos casos en los que podría suceder que intuitivamente se piense que la similitud debería rondar cierto valor (a nuestro juicio), pero que no resulta así. Tales son los casos como 'francia' y 'espana' (esta última es escrita así cuando el escritor tiene un teclado en inglés), 'pista' y 'carreras' o 'rico' y 'sabroso'. Estos casos pueden suceder porque no ocurrían en el mismo contexto lo suficiente como para impactar en el valor de similitud. Otro causante de esto es que la ventana de contexto utilizada (esto es, cuantas palabras se consideran hacia la derecha y hacia la izquierda de la palabra objetivo) no tenga un tamaño suficiente para recoger ciertas palabras en el contexto de la palabra objetivo, o también que la ventana no sea simétrica (por ejemplo, considera 8 palabras antes de la objetivo y 2 palabras luego de la misma). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el bloque de código a continuación realice lo siguiente:\n",
    "- Separe el corpus en palabras con nltk.wordpunct_tokenize (todas la partes: train, validacion y test)\n",
    "- Convierta las palabras a minúsculas dado que el repertorio de vectores está en minúsculas\n",
    "- Almacene las palabras resultantes en una variable llamada *vocabulario*. Considere una estructura adecuada para no tener palabras repetidas.\n",
    "- Despliegue en pantalla la cantidad de palabras de *vocabulario*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set()\n",
    "\n",
    "for comment in train + validation + test:\n",
    "    tokenizedComment = nltk.wordpunct_tokenize(comment[0].lower())\n",
    "    for word in tokenizedComment:\n",
    "        vocabulario.add(word)\n",
    "\n",
    "print(\"El vocabulario tiene \" + str(len(vocabulario)) + \" palabras.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construya los siguientes dos conjuntos:\n",
    "\n",
    "1. Palabras de *vocabulario* que tienen un vector asociado en el repertorio de vectores.\n",
    "2. Palabras de *vocabulario* que **no** tienen un vector en el repertorio de vectores.\n",
    "\n",
    "Imprima la cantidad de palabras de cada conjunto. Imprima además un muestreo de las palabras del conjunto 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasVector = set()\n",
    "hasVectorNot = set()\n",
    "\n",
    "for word in vocabulario:\n",
    "    try:\n",
    "        vec = vectors[wordToNum[word]]\n",
    "    except KeyError:\n",
    "        hasVectorNot.add(word)\n",
    "    hasVector.add(word)\n",
    "    \n",
    "print(\"Cantidad de palabras que tienen un vector asociado: {}\".format(len(hasVector)))\n",
    "print(\"Cantidad de palabras que NO tienen un vector asociado: {}\\n\".format(len(hasVectorNot)))\n",
    "\n",
    "for word in enumerate(list(hasVectorNot)):\n",
    "    print(word[1])\n",
    "    if (word[0] == 40): break;\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué observa en el muestreo de palabras que no tienen un vector asociado (conjunto 2)?\n",
    "\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Las 20 palabras impresas son en su mayoría palabras que tienen errores ortográficos o \"typos\" (abreviatura de _typographical error_ en español \"error tipográfico\"). Otras palabras que también aparecen en el muestreo son emoticones (en otras iteraciones se imprimió el emoticon ':$', el cual no aparece en el caso presentado ya que el orden de las palabras en el set es aleatorio), algunas puntuaciones \"extrañas\" (',....', '?\" o ') y palabras que son escritas haciendo énfasis en algun aspecto (como 'tiernisimos' o 'morcillitas') , como también algunas que, aunque no son tan raras, simplemente pueden no aparecen en el corpus de entrenamiento (como 'defruadaron' o 'porcioncitas') o son contracciones de una palabra con otra (como 'reamable' 0 'superfresaca'). También aparece una palabra que es una castellanización de otro idioma (como 'trabalhados').\n",
    "\n",
    "Esto es un suceso común, ya que los comentarios son escritos por personas de todo estrato social y edad, lo que lleva a que se encuentren palabras con faltas ortográficas o \"raras\". Además, es común que varias letras se intercambien por otras cuando se escribe en el teclado (\"typo\").\n",
    "También se debe considerar que los lenguajes se encuentran en constante evolución, y que dependiendo de los diferentes tiempos de donde se comparen texto, se pueden encontrar palabras que no existían en el espacio temporal de uno pero si en otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación vectorial de la oración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de Palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice una representación de bolsa de palabras con *stemming* para los comentarios del corpus considerando únicamente los conjuntos de entrenamiento y validación. Utilice la clase *sklearn.CountVectorizer* con una configuración de parámetros con considere adecuada. Esta representación será utilizada posteriormente para realizar clasificiación supervisada.\n",
    "\n",
    "**Sugerencia:** Utilice el parámetro *min_df* y *max_df* para reducir la dimensión del vector de la bolsa de palabras. Se sugiere que la dimensión de la representación sea menor a 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from copy import copy\n",
    "\n",
    "spanish_stemmer = SpanishStemmer()\n",
    "\n",
    "tokenRegex = '[a-záéíóúñ]{3,}'\n",
    "transf = sklearn.feature_extraction.text.CountVectorizer(max_df=0.2, min_df=400, ngram_range=(1,1), analyzer='word', \n",
    "                                                         lowercase=True, token_pattern=tokenRegex, stop_words=None)\n",
    "\n",
    "# Se define una nueva función que servira como nuevo parametro tokenizer del constructor CountVectorizer\n",
    "def stem_tokenizer(text):\n",
    "    tokenizer = transf.build_tokenizer()\n",
    "    return [spanish_stemmer.stem(word) for word in tokenizer(text)]\n",
    "\n",
    "trainCom = [comentario for (comentario, valor) in train]\n",
    "validationCom = [comentario for (comentario, valor) in validation]\n",
    "comments = trainCom + validationCom\n",
    "\n",
    "transf_with_stem = copy(transf).set_params(tokenizer=stem_tokenizer)\n",
    "transf_with_stem.fit(comments)\n",
    "\n",
    "vectores_with_stem = transf_with_stem.transform(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente bloque de código realice lo siguiente:\n",
    "\n",
    "- Despliegue la representacion (bow) de la oración presentada como ejemplo\n",
    "- Despliegue además la cantidad de palabras de la bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion_ej = 'Muy pero muy buena rica la comida y muy ricas tartas'\n",
    "\n",
    "# COMPLETE A PARTIR DE AQUI\n",
    "bow = transf_with_stem.transform([oracion_ej])\n",
    "print(\"La representación de la oración es: \" + str(bow))\n",
    "diccionario_with_stem = transf_with_stem.get_feature_names()\n",
    "print(\"La bolsa de palabras tiene \" + str(len(diccionario_with_stem)) + \" palabras.\")\n",
    "#print(vectores_with_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el bloque de código a continuación para definir la funcion *imprimir_tiempo*. Esta función despliega en pantalla el tiempo transcurrido a partir del timestamp pasado como parámetro. Si desea puede utilizarla para medir el tiempo de sus ejecuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def imprimir_tiempo(ts):\n",
    "    print(\"--- %s mins ---\" % (float(time.time() - ts)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente la función *data2Xy_bow* cuyo encabezado se presenta en el bloque de código a continuación. La función transforma en vectores a los comentarios con la bolsa de palabras almacenándolos en X y sus etiquetas en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2Xy_bow(bow, data):\n",
    "    X = bow.transform([comentario for (comentario, etiqueta) in data])\n",
    "    y = [etiqueta for (comentario,etiqueta) in data]\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere la lista de pares de comentarios *lista_comentarios*. En la lista *lista_comentarios_estudiante* escriba pares de comentarios que considere pertinentes para ver su similitud según el *bow* definido. Imprima en pantalla los comentarios de ambas listas junto a la similaridad obtenida según la representación de *bow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_comentarios = [\n",
    "    ('muy rica la comida, buenas pizzas', 'excelente pizza la salsa estaba muy rica'),\n",
    "    ('no me gustó para nada. mala atención', 'me pareció todo bastante malo'),\n",
    "    ('que buen servicio, hay que volver', 'excelente todo, me verán seguido por ahí'),\n",
    "    ('las tartas no me gustaron', 'muy bueno servicio'),\n",
    "]\n",
    "\n",
    "lista_comentarios_estudiante = [\n",
    "    ('Es todo muy muy rico y de alta calidad!', 'muy muy rico todo. servicios excellente. buen curry.'),\n",
    "    ('Guijón: Por favor no cambien nunca. Gracias', 'caro y malo no volveria nunca mas'),\n",
    "    ('Horrible. Muy mala comida y carísimo.', 'carisimo, la comida horrible!!!!!!!!!!!!'),\n",
    "    ('En los rubros ambiente, atención y comida, lo mejor de Palermo.', 'mala atencion y falta de buena comida y ambiente, cambien de rubro.')\n",
    "]\n",
    "\n",
    "# COMPLETE A PARTIR DE AQUI\n",
    "for par in lista_comentarios + lista_comentarios_estudiante:\n",
    "    vs = transf_with_stem.transform(par)\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(par[0], par[1], similarity(vs.toarray()[0], vs.toarray()[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroide de vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta parte se representará cada comentario como el centroide de los vectores de las palabras que lo forman. Se pide implementar la función *txt2vec* que dado un comentario y el repertorio de vectores calcula el promedio de los vectores de las palabras del comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2vec(vectores, comentario):\n",
    "    comment_words = nltk.wordpunct_tokenize(comentario.lower())       \n",
    "    vectores_comentario = [getVector(vectores, word) for word in comment_words] \n",
    "            \n",
    "    if (len(vectores_comentario) == 0):\n",
    "        return np.zeros(totalColumnsVectors)\n",
    "    \n",
    "    return np.mean(vectores_comentario, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente la función *data2Xy_vec* cuyo encabezado se presenta en el bloque de código a continuación. La función transforma a los comentarios en su representación de centroide de vectores (las filas de X) y sus etiquetas son las componente del vector y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2Xy_vec(vec, data):        \n",
    "    X = [txt2vec(vec, comentario) for (comentario, etiqueta) in data]\n",
    "    y = [etiqueta for (comentario, etiqueta) in data]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue en pantalla los pares de comentarios de *lista_comentarios* y *lista_comentarios_estudiante* junto con la similitud de sus representaciones de centroide de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_centroides(c1, c2):\n",
    "    centroides_palabras_c1 = txt2vec(vectors, c1)\n",
    "    centroides_palabras_c2 = txt2vec(vectors, c2)\n",
    "    \n",
    "    return similarity(centroides_palabras_c1, centroides_palabras_c2)\n",
    "\n",
    "for c1,c2 in lista_comentarios + lista_comentarios_estudiante:    \n",
    "    similitud_par_comentarios = similitud_centroides(c1, c2)\n",
    "    print(\"La similitud entre '{}' y '{}' es {}.\".format(c1, c2, similitud_par_comentarios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comente los resultados de similitud de oraciones obtenidos con las representaciones de bolsa de palabras y las de centroide de vectores.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "En general las similitudes obtenidas con bolsa de palabras son más bajas debido a que solo se miran palabras cuya raíz coincida con la raíz de palabras en el otro comentario, y no necesariamente la similitud (semántica) de dos comentarios implica que se compartan palabras, e incluso comentarios relativamente parecidos dan una similitud de 0.\n",
    "En cambio con centroide de vectores se logra detectar similitudes semánticas más allá de tener o no las mismas palabras, pero a su vez puede suceder que oraciones muy diferentes tengan centroides muy cercanos entre sí debido a meras casualidades que pudieron ocurrir en el corpus con el que se construyeron los vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta sección entrene un clasificador *SVM* de *sklearn* para ambas representaciones (centroide de vectores y bolsa de palabras). Busque una configuración de hiperparámetros adecuada utilizando como referencia el conjunto de validación. Utilice para comparar resultados la medida *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data2Xy_bow(transf_with_stem, train)\n",
    "clf = sklearn.svm.LinearSVC(C=22, max_iter=100000)\n",
    "ti = time.time()\n",
    "clf.fit(X, y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval, yval = data2Xy_bow(transf_with_stem, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(clf.score(Xval, yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centroide_train,y_centroide_train = data2Xy_vec(vectors, train)\n",
    "\n",
    "SVM_centroide = sklearn.svm.LinearSVC(C=22, max_iter=10000)\n",
    "ti = time.time()\n",
    "SVM_centroide.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centroide_val, y_centroide_val = data2Xy_vec(vectors, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(SVM_centroide.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue los resultados obtenidos con *SVM* para ambas representaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierResult(classifier, X, y, modelText):\n",
    "    predicted = classifier.predict(X)\n",
    "    conf = sklearn.metrics.confusion_matrix(y, predicted)\n",
    "    tp, tn, fp, fn = conf[1][1], conf[0][0], conf[0][1], conf[1][0]\n",
    "    print(\"\\nPara el modelo de {} se obtiene lo siguiente:\".format(modelText))\n",
    "    print(\"Hay {} verdaderos positivos, {} verdaderos negativos, {} falsos positivos, {} falsos negativos\".format(tp, tn, fp, fn))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1Score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Precision: {}, recall: {}, Fscore: {}\".format(precision, recall, f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printClassifierResult(clf, Xval, yval, \"SVM con Bag of Words\")\n",
    "printClassifierResult(SVM_centroide, X_centroide_val, y_centroide_val, \"SVM con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Fowrward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta sección utilizará un clasificador de red neuronal *feed forward* (*multilayer perceptron* - MLP) para realizar la clasificación de sentimiento de los comentarios considerando ambas representaciones: centroide de vectores y bolsa de palabras. Busque una configuración de hiperparámetros adecuada tomando como referencia la medida de *accuracy* obtenida en el conjunto de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clfNN = MLPClassifier(solver='adam', alpha=1e-5, batch_size=500, max_iter=500, learning_rate='adaptive', hidden_layer_sizes=(5, 2), shuffle=False, activation='identity', tol=1e-4)\n",
    "ti = time.time()\n",
    "clfNN.fit(X,y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)\n",
    "\n",
    "ti = time.time()\n",
    "print(\"\\nAccuracy: \" + str(clfNN.score(Xval,yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_centroide = MLPClassifier(solver='adam', alpha=1e-10, batch_size=500, max_iter=500, learning_rate='adaptive', hidden_layer_sizes=(5, 2), shuffle=False, activation='identity', tol=1e-4)\n",
    "ti = time.time()\n",
    "NN_centroide.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)\n",
    "\n",
    "ti = time.time()\n",
    "print(\"\\nAccuracy: \" + str(NN_centroide.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue los mejores resultados obtenidos para ambas representaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printClassifierResult(clfNN, Xval, yval, \"Feed Forward Neural Network con Bag of Words\")\n",
    "printClassifierResult(NN_centroide, X_centroide_val, y_centroide_val, \"Feed Forward Neural Network con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores Resultados en Validación\n",
    "\n",
    "Analice los resultados obtenidos con cada clasificador y cada representación en el conjunto de validación. \n",
    "\n",
    "Tenga en cuenta que debe considerar al menos los siguientes 4 clasificadores:\n",
    "\n",
    "- SVM con BOW\n",
    "- SVM con Centroide\n",
    "- MLP con BOW\n",
    "- MLP con Centroide\n",
    "\n",
    "Realice los comentarios que considere adecuados respecto a la comparación y resultados obtenidos. Si lo desea puede agregar bloques de código que muestren resultados adicionales.\n",
    "\n",
    "**Respuesta:** \n",
    "###### SVM:\n",
    "\n",
    "En el caso de SVM, se probaron dos implementaciones del clasificador SVM: LinearSVC y SVC. En cuanto a la comparación entre resultados obtenidos, son similares en las dos implementaciones. En la primera se obtuvieron mejores resultados utilizando la representación de centroides y en la segunda se obtuvo una pequeña mejora utilizando la representación de bolsa de palabras. En relación a la performance, la segunda resulta demorar menos. Esto puede suceder por las diferencias de implementacón entre las dos funcionalides o porque el hecho de desactivar el shrinking para mejorar los resultados (lo cual cuando se activa mejora los tiempos) permite obtener mejores resultados. \n",
    "\n",
    "Respecto a la comparación entre los resultados obtenidos para las dos representaciones, si tomamos el valor F (_Fscore_) como medida de correctitud general, se ve que el clasificador SVM con representación de centroide mejora levemente al clasificador SVM con representación de bolsa de palabras. Esto puede deberse a que la representación de centroides recoge aspectos estadísticos a un nivel más global que el caso de bag of words, para la cual se consideran menos palabras.\n",
    "El otro aspecto a evaluar es que se percibe una mejora significativa en el tiempo de entrenamiento y validación para el caso en que se utiliza la representación de centroides. Esto sucede ya que los vectores de dicha representación tienen una menor cantidad de features que los que se obtienen utilizando la representación de bolsa de palabras (300 en representación de centroides, 486 en bolsa de palabras).\n",
    "\n",
    "###### SVM vs. MLP:\n",
    "\n",
    "El primer factor que salta a la vista es la diferencia de performance de tiempo computacional. El clasificador que utiliza la red neuronal posee una amplia mejora (tanto en tiempo de entrenamiento como de validación) con respecto a los dos clasificadores que utilizan SVM.\n",
    "\n",
    "Prosiguiendo con los resultados en la validación se puede ver que en el caso del clasificador MLP, presenta un valor F similar al clasificador SVM para el caso de la representación con centroides (considerando la implementación LinearSVC), y apenas menor para el caso de la representación de bolsa de palabras (considerando la implementación SVC).\n",
    "\n",
    "Yendo a los resultados más concretos, el clasificador LinearSVC obtiene los mejores valores con respecto a la cantidad de ejemplos clasificados correctamente. En relación a los ejemplos clasificados incorrectamente, se obtienen resultados mixtos: el clasificador MLP empeora la cantidad de falsos positivos en relación con LinearSVC (no así con SVC) cuando se utiliza la representación de centroides, pero reduce la cantidad de falsos negativos en relación a las 2 implementaciones. Para el caso de la representación de comentarios con bolsa de palabras, sucede lo mismo descrito anteriormente para los falsos negativos, pero no para los falsos positivos, en donde se obtiene el mejor resultados para SVC, seguido por el clasificador MLP y, por último, el clasificador LinearSVC.\n",
    "\n",
    "Podemos ver estos resultados proyectados en una **precision** máxima obtenida para LinearSVC con centroides (y con un poco menos MLP con centroides) debido a la alta cantidad de ejemplos clasificados correctamente. En cuanto a la **recall**, la máxima se obtuvo para MLP con centroides. Esto nos indica que los mejores resultados se obtuvieron con LinearSVC y MLP, ambos utilizando la representación con centroides.\n",
    "\n",
    "Podemos concluir entonces que, para el corpus de comentarios, aunque los dos clasificadores (y las dos implementaciones del clasificador SVM) arrojan resultados similares para ambas representaciones de comentarios, el clasificador MLP presenta una mejora en cuanto a tiempo computacional y en la calidad de resultados en general que puede inclinar la balanza a su favor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasificador SVM implementado en SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data2Xy_bow(transf_with_stem, train)\n",
    "clf2 = sklearn.svm.SVC(kernel='linear',shrinking=False)\n",
    "ti = time.time()\n",
    "clf2.fit(X, y)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval, yval = data2Xy_bow(transf_with_stem, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(clf2.score(Xval, yval)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centroide_train,y_centroide_train = data2Xy_vec(vectors, train)\n",
    "\n",
    "SVM_centroide2 = sklearn.svm.SVC(kernel='linear',shrinking=False)\n",
    "ti = time.time()\n",
    "SVM_centroide2.fit(X_centroide_train, y_centroide_train)\n",
    "print(\"Tiempo de entrenamiento: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centroide_val, y_centroide_val = data2Xy_vec(vectors, validation)\n",
    "ti = time.time()\n",
    "print(\"Accuracy: \" + str(SVM_centroide2.score(X_centroide_val, y_centroide_val)))\n",
    "print(\"Tiempo de validación: \\n\")\n",
    "imprimir_tiempo(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierResult(classifier, X, y, modelText):\n",
    "    predicted = classifier.predict(X)\n",
    "    conf = sklearn.metrics.confusion_matrix(y, predicted)\n",
    "    tp, tn, fp, fn = conf[1][1], conf[0][0], conf[0][1], conf[1][0]\n",
    "    print(\"\\nPara el modelo de {} se obtiene lo siguiente:\".format(modelText))\n",
    "    print(\"Hay {} verdaderos positivos, {} verdaderos negativos, {} falsos positivos, {} falsos negativos\".format(tp, tn, fp, fn))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1Score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Precision: {}, recall: {}, Fscore: {}\".format(precision, recall, f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printClassifierResult(clf2, Xval, yval, \"SVM con Bag of Words\")\n",
    "printClassifierResult(SVM_centroide2, X_centroide_val, y_centroide_val, \"SVM con Centroides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall y Matriz de Confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule la medida de *accuracy* en el conjunto de *test* para los modelos de la parte anterior. Despliegue los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest, ytest = data2Xy_bow(transf_with_stem, test)\n",
    "X_centroide_test,y_centroide_test = data2Xy_vec(vectors, test)\n",
    "\n",
    "print(\"SVM bow tiene accuracy {} para el conjunto de test\".format(clf.score(Xtest, ytest)))\n",
    "print(\"FF NN bow tiene accuracy {} para el conjunto de test\".format(clfNN.score(Xtest, ytest)))\n",
    "print(\"SVM centroide tiene accuracy {} para el conjunto de test\".format(SVM_centroide.score(X_centroide_test, y_centroide_test)))\n",
    "print(\"FF NN centroide tiene accuracy {} para el conjunto de test\".format(NN_centroide.score(X_centroide_test, y_centroide_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Seleccione uno de los modelos y analice sus errores en función de la matriz de confusión. Compute las medidas de *precision*, *recall* y *F*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printClassifierResult(clfNN, Xtest, ytest, \"Feed Forward Neural Network con Bag of Words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliegue algunos casos de falsos positivos y falsos negativos del clasificador seleccionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clfNN.predict(Xtest)\n",
    "\n",
    "print(\"######### Falsos positivos #########\\n\")\n",
    "\n",
    "# falsos positivos\n",
    "total_fp_printed = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 'POS' and predicted[i] != ytest[i]:\n",
    "        print(test[i])\n",
    "        total_fp_printed += 1\n",
    "    if total_fp_printed == 10: \n",
    "        break;\n",
    "        \n",
    "print(\"\\n######### Falsos negativos #########\\n\")\n",
    "\n",
    "# falsos negativos\n",
    "total_fn_printed = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 'NEG' and predicted[i] != ytest[i]:\n",
    "        print(test[i])\n",
    "        total_fn_printed += 1\n",
    "    if total_fn_printed == 10: \n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo de oraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Utilice cada uno de los clasificadores considerados anteriormente para cada comentario de *lista_comentarios* y *lista_comentarios_estudiante*.\n",
    "\n",
    "Despliegue en pantalla cada comentario junto con la salida obtenida por cada clasificador. Realice los comentarios que considere pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios = [y for x in ([c1, c2] for c1,c2 in lista_comentarios + lista_comentarios_estudiante) for y in x]\n",
    "\n",
    "for comentario in comentarios:\n",
    "    X_comment = transf_with_stem.transform([comentario])\n",
    "    X_centroide = txt2vec(vectors, comentario)\n",
    "    print()\n",
    "    print(\"'{}' fue clasificado como: \\n'{}', '{}', '{}', '{}' \\npara BOW con NN, BOW con SVM, centroide de vectores con NN y centroide de vectores con SVM respectivamente\".format(comentario, clfNN.predict(X_comment)[0], clf.predict(X_comment)[0], NN_centroide.predict([X_centroide])[0], SVM_centroide.predict([X_centroide])[0]))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
